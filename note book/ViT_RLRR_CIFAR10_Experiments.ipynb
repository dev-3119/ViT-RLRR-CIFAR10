{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 12:49:17.210297: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-04 12:49:17.220374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741072757.231983   25901 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741072757.235590   25901 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-04 12:49:17.246996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Step 1: Define the Custom RLRR Layer (Adaptation Module)\n",
    "# ==========================================================\n",
    "class RLRRDense(layers.Layer):\n",
    "    def __init__(self, units, use_bias=True, kernel_initializer='glorot_uniform', **kwargs):\n",
    "        super(RLRRDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_dim = int(input_shape[-1])\n",
    "        self.W_frozen = self.add_weight(\n",
    "            shape=(input_dim, self.units),\n",
    "            initializer=self.kernel_initializer,\n",
    "            trainable=False,\n",
    "            name=\"W_frozen\"\n",
    "        )\n",
    "        self.s_left = self.add_weight(\n",
    "            shape=(input_dim, 1),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name=\"s_left\"\n",
    "        )\n",
    "        self.s_right = self.add_weight(\n",
    "            shape=(1, self.units),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name=\"s_right\"\n",
    "        )\n",
    "        self.f = self.add_weight(\n",
    "            shape=(input_dim, self.units),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name=\"f_bias\"\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                shape=(self.units,),\n",
    "                initializer=\"zeros\",\n",
    "                trainable=True,\n",
    "                name=\"bias\"\n",
    "            )\n",
    "        else:\n",
    "            self.bias = None\n",
    "        super(RLRRDense, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        scaling = 1 + tf.matmul(self.s_left, self.s_right)\n",
    "        W_reparam = scaling * self.W_frozen + self.f\n",
    "        output = tf.matmul(inputs, W_reparam)\n",
    "        if self.use_bias:\n",
    "            output = tf.nn.bias_add(output, self.bias)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Step 2: Load a Pre-trained ViT Backbone from TensorFlow Hub\n",
    "# ==========================================================\n",
    "vit_url = \"https://tfhub.dev/sayakpaul/vit_b16_fe/1\"\n",
    "vit_layer = hub.KerasLayer(vit_url, trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Step 3: Build the Fine-Tuning Model\n",
    "# ==========================================================\n",
    "input_img = tf.keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "# Normalize input\n",
    "x = layers.Rescaling(1./255.0)(input_img)\n",
    "\n",
    "# ✅ FIX: Wrap `hub.KerasLayer` in a Lambda layer to prevent symbolic tensor errors\n",
    "features = layers.Lambda(lambda img: vit_layer(img))(x)\n",
    "\n",
    "# Add RLRR adaptation layer\n",
    "x = RLRRDense(256, use_bias=True)(features)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "# Add a classification head\n",
    "output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Construct the full model\n",
    "model = Model(inputs=input_img, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Step 4: Load and Prepare the Dataset Efficiently\n",
    "# ==========================================================\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# ✅ Efficient Data Pipeline (No OOM Errors)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(tf.cast(image, tf.float32), (224, 224))  # Resize dynamically\n",
    "    return image, label\n",
    "\n",
    "train_ds = (tf.data.Dataset.from_tensor_slices((x_train, y_train_cat))\n",
    "            .map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "            .batch(64)\n",
    "            .prefetch(AUTOTUNE))\n",
    "\n",
    "test_ds = (tf.data.Dataset.from_tensor_slices((x_test, y_test_cat))\n",
    "           .map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "           .batch(64)\n",
    "           .prefetch(AUTOTUNE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Step 5: Compile and Train the Model\n",
    "# ==========================================================\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history =model.fit(train_ds,\n",
    "          validation_data=test_ds,\n",
    "          epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Step 6: Evaluate the Model\n",
    "# ==========================================================\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model.save(\"vit_finetuned_rlrr_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
